{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayPatel-SE/4ML3_Assignment2/blob/main/Winter_24_4ML3_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPyo0sFQnV3J"
      },
      "source": [
        "# Practicing PCA on a Face Dataset\n",
        "In this exercise, we explore the application of the PCA on the LFW (Labeled Faces in the Wild) dataset which is available through the sklearn package.\n",
        "# Submission\n",
        "- There are three tasks for you.\n",
        "- Report the results and answer the questions in the pdf file that you would submit along with your other solutions.\n",
        "- Additionally, submit your code in the same Jupiter notebook format. (keep the overal format of the notebook unchanged)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsP0SbpUnV3P"
      },
      "source": [
        "# Packages\n",
        "First of all, let's import the packages we need for this assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CngSxXknV3P"
      },
      "outputs": [],
      "source": [
        "# loading need libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.linalg import svd\n",
        "from sklearn.datasets import fetch_lfw_people"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LH8pp2XnV3R"
      },
      "source": [
        "# Dataset characteristics\n",
        "Here we load the data set and take a look at the structure/properties of the dataset. This step is slow, but once the data set is loaded we do not need to repeat it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRrzePmGnV3R"
      },
      "outputs": [],
      "source": [
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=1)\n",
        "n_samples, image_height, image_width = lfw_people.images.shape\n",
        "\n",
        "X = lfw_people.data\n",
        "# the label to predict is the id of the person\n",
        "Y = lfw_people.target\n",
        "Y_names = lfw_people.target_names\n",
        "n_classes = Y_names.shape[0]\n",
        "\n",
        "print(\"Dataset properties:\")\n",
        "print(\"\\t Number of data points: %d\" % X.shape[0])\n",
        "print(\"\\t Number of features: %d\" % X.shape[1])\n",
        "print(\"\\t Number of classes: %d\" % n_classes)\n",
        "print(\"\\t Width of each image: %d\" % image_width)\n",
        "print(\"\\t Height of each image: %d\" % image_height)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72iwzi88nV3S"
      },
      "source": [
        "# Showing the pictures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "NZO8YZ1BnV3T"
      },
      "outputs": [],
      "source": [
        "def plot_faces(images, labels, names, n_row, n_col):\n",
        "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
        "    f = plt.figure(figsize=(8,3))\n",
        "    for i in range(n_row * n_col):\n",
        "        subfigure = f.add_subplot(n_row, n_col, i + 1)\n",
        "        subfigure.imshow(images[i].reshape((image_height, image_width)), cmap=plt.cm.gray)\n",
        "        subfigure.set_title(names[labels[i]])\n",
        "        # Removing the axes\n",
        "        plt.xticks(())\n",
        "        plt.yticks(())\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_faces(X, Y, Y_names, 2, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select \"Tony Blair\" class\n",
        "Run the below code to select a specific class of faces."
      ],
      "metadata": {
        "id": "eUYnR4cLimZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_name_bush = 'Tony Blair'\n",
        "class_indx_bush = list(Y_names).index(class_name_bush)\n",
        "X_bush = X[Y==class_indx_bush,:]\n",
        "Y_bush = Y[Y==class_indx_bush]\n",
        "\n",
        "plot_faces(X_bush, Y_bush, Y_names, 2, 5)"
      ],
      "metadata": {
        "id": "66gSx_-liks-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcwRA6dtnV3U"
      },
      "source": [
        "# <font color=\"red\">Task 1: Eigenfaces (10 points) </font>\n",
        "\n",
        "The below code is supposed to generate the \"average faces\" as well as the first \"eigen faces\" for Tony Blair class. In this section you need to implement centralize_data() and pca_components() functions.\n",
        "\n",
        "We use SVD factorization in order to implement PCA. In the following link you can find useful information of how to do so. It explains the connection between PCA and SVD. https://stats.stackexchange.com/questions/134282/relationship-between-svd-and-pca-how-to-use-svd-to-perform-pca\n",
        "\n",
        "\n",
        "You may check the video with link https://youtu.be/nbBvuuNVfco?si=SfJSE85fjMUMiboK for a detailed explanation of SVD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxUpOcEznV3U"
      },
      "outputs": [],
      "source": [
        "def centralize_data(images):\n",
        "    # Implement this function. Subtract the data mean from datapoints.\n",
        "    # Return centralized data and data mean\n",
        "    # 5 points\n",
        "\n",
        "    return c_data , data_mean\n",
        "\n",
        "def normalized_svd(images):\n",
        "    # SVD is a matrix factorization which helps us to implement PCA.\n",
        "    # Follow the given link above to understand how it works.\n",
        "    # This function first centralizes the data points, and returns SVD factorization of the data set.\n",
        "    XN, data_mean = centralize_data(images)\n",
        "    U,S,Vt = svd(XN)\n",
        "    return U,S,Vt,data_mean\n",
        "\n",
        "def pca_components(Vt, n_components):\n",
        "    # Implement this function.\n",
        "    # Return first n components (first n principal directions/axes)\n",
        "    # 5 points\n",
        "\n",
        "    return components\n",
        "\n",
        "def average_image_class(images):\n",
        "    class_average = np.mean(images, axis = 0)\n",
        "    return class_average\n",
        "\n",
        "def eigen_face_class(images):\n",
        "    _,_,Vt,_ = normalized_svd(images)\n",
        "    return pca_components(Vt, n_components=1)\n",
        "\n",
        "def plot_class_representatives(images, class_name, aggregator):\n",
        "    f = plt.figure(figsize=(2,2))\n",
        "    subfigure = f.add_subplot(1,1,1)\n",
        "    class_representative = aggregator(images)\n",
        "\n",
        "    subfigure.imshow(class_representative.reshape((image_height, image_width)), cmap=plt.cm.gray)\n",
        "    subfigure.set_title(class_name)\n",
        "    # Removing the axes\n",
        "    plt.xticks(())\n",
        "    plt.yticks(())\n",
        "    plt.show()\n",
        "\n",
        "plot_class_representatives(X_bush, class_name_bush, aggregator=average_image_class)\n",
        "plot_class_representatives(X_bush, class_name_bush, aggregator=eigen_face_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PueD1sNnV3V"
      },
      "source": [
        "# <font color=\"red\">Task 2: PCA visualization (10 points) </font>\n",
        "It is hard to visualize and get a sense of highdimensional data. One approach to address this problem is dimensionality reduction, as we discussed in class. Here, we project the data into the 2D plane to be able to \"see\" what is going on. Implement the pca_transform() function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56h2K0fcnV3W"
      },
      "outputs": [],
      "source": [
        "def pca_transform(U,S, n_components):\n",
        "    # Implement this function.\n",
        "    # Return transformed data using first n components.\n",
        "    # Basically you have to return transformed 2D data\n",
        "    # 10 points\n",
        "\n",
        "    return transformed_data\n",
        "\n",
        "U,S,Vt,data_mean = normalized_svd(X_bush)\n",
        "T = pca_transform(U,S, n_components=2)\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "plt.plot(T[:, 0], T[:, 1], 'o')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHWr-8vtnV3W"
      },
      "source": [
        "# <font color=\"red\">Task 3: Reconstructing images (5 points)</font>\n",
        "Some information is naturally lost when reducing the dimensionality of the data (just like the above scatter plot). In this part use the PCA (applied to the whole data set) to reduce the dimensionality of the data points to 2. Then, transform the 2D data points back to the original space to reconstruct the images. Implement pca_inverse_transform() function.\n",
        "\n",
        " - Plot the first 5 images in the data set and include it in your pdf report."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pca_inverse_transform(transformed_data, components, data_mean):\n",
        "    # Implement this function.\n",
        "    # Return inverse transformed data.\n",
        "    # Previously you derived transformed data (into lower dimension). Now you have to transformed it back into original space.\n",
        "    # 5 points\n",
        "\n",
        "    return reconstructed_data\n",
        "\n",
        "plot_faces(pca_inverse_transform(T, Vt[:2,:], data_mean),Y_bush, Y_names, 1, 5)"
      ],
      "metadata": {
        "id": "_UIdVowbSR7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmOELH8inV3X"
      },
      "source": [
        "# <font color=\"red\">Task 3: Average Reconstruction Error (20 points)</font>\n",
        "Separate the image dataset into train (100 images) and test (rest of the data) datasets.\n",
        "Train PCA with [2, 10, 30, 60, 100] components respectively. Reconstruction error is defined as $error=(\\sum_{i=1}^n||x_i-reconstruct(pca(x_i))||^2_2)/n$, where $n$ is the number of images.\n",
        "\n",
        "Plot average reconstruction error on training and testing data points with the following requirements:\n",
        "  1. X-axis shows number of components.\n",
        "  2. Y-axis shows reconstruction error.\n",
        "  3. Draw two graphs, one for training and the other line for testing.\n",
        "\n",
        "(15 points)\n",
        "\n",
        "Explain the difference between the two graphs (5 points)."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tmGBg0jFSSjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gm2Ht4tWSTEH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.11"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GPyo0sFQnV3J"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}